{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "anand IMG_20200822_182330.jpg dataset_1\n",
      "suryansh IMG_20200822_173110.jpg dataset_1\n",
      "suryansh IMG_20200822_172757.jpg dataset_1\n",
      "swarn IMG20200822171139.jpg dataset_1\n",
      "suryansh IMG_20200822_173105.jpg dataset_1\n",
      "sujeet IMG_20200822_192018.jpg dataset_1\n",
      "suryansh IMG_20200822_173227.jpg dataset_1\n",
      "suryansh IMG_20200822_173130.jpg dataset_1\n",
      "swarn IMG20200822165959.jpg dataset_1\n",
      "suryansh IMG_20200822_172844.jpg dataset_1\n",
      "sujeet IMG_20200822_192437.jpg dataset_1\n",
      "suryansh IMG_20200822_172926.jpg dataset_1\n",
      "swarn IMG20200822165858.jpg dataset_1\n",
      "sujeet IMG_20200822_192044.jpg dataset_1\n",
      "anand IMG_20200822_182513.jpg dataset_1\n",
      "suryansh IMG_20200822_171929.jpg dataset_1\n",
      "swarn IMG20200822165918.jpg dataset_1\n",
      "suryansh IMG_20200822_172918.jpg dataset_1\n",
      "sujeet IMG_20200822_192542.jpg dataset_1\n",
      "swarn IMG20200822170345.jpg dataset_1\n",
      "anand IMG_20200822_182321.jpg dataset_1\n",
      "suryansh IMG_20200822_171922.jpg dataset_1\n",
      "swarn IMG20200822170206.jpg dataset_1\n",
      "swarn IMG20200822165928.jpg dataset_1\n",
      "anand IMG_20200822_182255.jpg dataset_1\n",
      "anand IMG_20200822_165640.jpg dataset_1\n",
      "suryansh IMG_20200822_172922.jpg dataset_1\n",
      "swarn IMG20200822165941.jpg dataset_1\n",
      "anand IMG_20200822_182848.jpg dataset_1\n",
      "swarn IMG20200822171308.jpg dataset_1\n",
      "anand IMG_20200822_182556.jpg dataset_1\n",
      "sujeet IMG_20200822_192550.jpg dataset_1\n",
      "sujeet IMG_20200822_192234.jpg dataset_1\n",
      "sujeet IMG_20200822_192525.jpg dataset_1\n",
      "suryansh IMG_20200822_172003.jpg dataset_1\n",
      "sujeet IMG_20200822_192108.jpg dataset_1\n",
      "suryansh IMG_20200822_172009.jpg dataset_1\n",
      "sujeet IMG_20200822_192051.jpg dataset_1\n",
      "sujeet IMG_20200822_192954.jpg dataset_1\n",
      "sujeet IMG_20200822_192106.jpg dataset_1\n",
      "sujeet IMG_20200822_192945.jpg dataset_1\n",
      "sujeet IMG_20200822_192737.jpg dataset_1\n",
      "swarn IMG20200822170006.jpg dataset_1\n",
      "anand IMG_20200822_182652.jpg dataset_1\n",
      "suryansh IMG_20200822_171932.jpg dataset_1\n",
      "suryansh IMG_20200822_171949.jpg dataset_1\n",
      "anand IMG_20200822_182717.jpg dataset_1\n",
      "sujeet IMG_20200822_192144.jpg dataset_1\n",
      "swarn IMG20200822170215.jpg dataset_1\n",
      "swarn IMG20200822170404.jpg dataset_1\n",
      "anand IMG_20200822_182741.jpg dataset_1\n",
      "anand IMG_20200822_182241.jpg dataset_1\n",
      "sujeet IMG_20200822_192902.jpg dataset_1\n",
      "suryansh IMG_20200822_172747.jpg dataset_1\n",
      "anand IMG_20200822_182536.jpg dataset_1\n",
      "sujeet IMG_20200822_192446.jpg dataset_1\n",
      "swarn IMG20200822171246.jpg dataset_1\n",
      "sujeet IMG_20200822_192242.jpg dataset_1\n",
      "anand IMG_20200822_165653.jpg dataset_1\n",
      "swarn IMG20200822170244.jpg dataset_1\n",
      "suryansh IMG_20200822_172804.jpg dataset_1\n",
      "suryansh IMG_20200822_172825.jpg dataset_1\n",
      "sujeet IMG_20200822_192102.jpg dataset_1\n",
      "sujeet IMG_20200822_192425.jpg dataset_1\n",
      "sujeet IMG_20200822_192103.jpg dataset_1\n",
      "anand IMG_20200822_182340.jpg dataset_1\n",
      "suryansh IMG_20200822_173119.jpg dataset_1\n",
      "anand IMG_20200822_182501.jpg dataset_1\n",
      "suryansh IMG_20200822_172742.jpg dataset_1\n",
      "sujeet IMG_20200822_192941.jpg dataset_1\n",
      "anand IMG_20200822_182234.jpg dataset_1\n",
      "sujeet IMG_20200822_192046.jpg dataset_1\n",
      "sujeet IMG_20200822_192251.jpg dataset_1\n",
      "sujeet IMG_20200822_192339.jpg dataset_1\n",
      "anand IMG_20200822_182412.jpg dataset_1\n",
      "sujeet IMG_20200822_192438.jpg dataset_1\n",
      "swarn IMG20200822170229.jpg dataset_1\n",
      "swarn IMG20200822170350.jpg dataset_1\n",
      "suryansh IMG_20200822_172931.jpg dataset_1\n",
      "swarn IMG20200822170223.jpg dataset_1\n",
      "anand IMG_20200822_182540.jpg dataset_1\n",
      "swarn IMG20200822170348.jpg dataset_1\n",
      "sujeet IMG_20200822_192247.jpg dataset_1\n",
      "swarn IMG20200822170331.jpg dataset_1\n",
      "anand IMG_20200822_182550.jpg dataset_1\n",
      "anand IMG_20200822_165128.jpg dataset_1\n",
      "swarn IMG20200822171149.jpg dataset_1\n",
      "swarn IMG20200822170334.jpg dataset_1\n",
      "sujeet IMG_20200822_192920.jpg dataset_1\n",
      "swarn IMG20200822170457.jpg dataset_1\n",
      "sujeet IMG_20200822_192702.jpg dataset_1\n",
      "swarn IMG20200822170341.jpg dataset_1\n",
      "suryansh IMG_20200822_173141.jpg dataset_1\n",
      "suryansh IMG_20200822_173039.jpg dataset_1\n",
      "swarn IMG20200822165627.jpg dataset_1\n",
      "anand IMG_20200822_182803.jpg dataset_1\n",
      "suryansh IMG_20200822_172755.jpg dataset_1\n",
      "swarn IMG20200822170240.jpg dataset_1\n",
      "suryansh IMG_20200822_172913.jpg dataset_1\n",
      "suryansh IMG_20200822_171938.jpg dataset_1\n",
      "sujeet IMG_20200822_191931.jpg dataset_1\n",
      "anand IMG_20200822_182854.jpg dataset_1\n",
      "swarn IMG20200822170338.jpg dataset_1\n",
      "swarn IMG20200822171232.jpg dataset_1\n",
      "anand IMG_20200822_182225.jpg dataset_1\n",
      "sujeet IMG_20200822_192705.jpg dataset_1\n",
      "suryansh IMG_20200822_172840.jpg dataset_1\n",
      "anand IMG_20200822_182347.jpg dataset_1\n",
      "suryansh IMG_20200822_172744.jpg dataset_1\n",
      "swarn IMG20200822170356.jpg dataset_1\n",
      "suryansh IMG_20200822_173114.jpg dataset_1\n",
      "anand IMG_20200822_182429.jpg dataset_1\n",
      "swarn IMG20200822171203.jpg dataset_1\n",
      "anand IMG_20200822_182522.jpg dataset_1\n",
      "sujeet IMG_20200822_191851.jpg dataset_1\n",
      "sujeet IMG_20200822_192039.jpg dataset_1\n",
      "sujeet IMG_20200822_192054.jpg dataset_1\n",
      "swarn IMG20200822165923.jpg dataset_1\n",
      "anand IMG_20200822_182220.jpg dataset_1\n",
      "anand IMG_20200822_182455.jpg dataset_1\n",
      "suryansh IMG_20200822_172929.jpg dataset_1\n",
      "(90, 1024)\n",
      "[3]\n",
      "[0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Data Preparation\n",
    "\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "imagePaths = sorted(list(paths.list_images(\"dataset_1\")))\n",
    "#print(imagePaths[0])\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "#print(imagePaths[0])\n",
    "#name = imagePaths[0].split(os.path.sep)[-2]\n",
    "#print(label)\n",
    "#data = np.array([0][])\n",
    "labels = None\n",
    "indes = np.array([[0],])\n",
    "print(indes.shape)\n",
    "label = [\"anand\",\"swarn\",\"suryansh\",\"sujeet\" ]\n",
    "#ind = label.index(\"DISGUST\")\n",
    "#print(ind)\n",
    "data = None\n",
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (32, 32))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #print(gray)\n",
    "    gray = gray.reshape(1, 1024)\n",
    "    #print(gray)\n",
    "    name = imagePath.split(os.path.sep)[-2]\n",
    "    print(imagePath.split(os.path.sep)[-2], imagePath.split(os.path.sep)[-1],  imagePath.split(os.path.sep)[-3])\n",
    "    \n",
    "    ind = label.index(name)\n",
    "    indes[0][0] = ind\n",
    "    if data is None:\n",
    "        data = gray\n",
    "        labels = indes\n",
    "    else:\n",
    "        data = np.vstack((data, gray))\n",
    "        labels = np.vstack((labels, indes))\n",
    "        #break;\n",
    "    #print(gray.shape)\n",
    "    #data.append(gray)\n",
    "    #print(labels.shape)\n",
    "#print(data.shape)\n",
    "#print(labels[3,])\n",
    "data = np.array(data, dtype=\"float\")\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.25, random_state=42)\n",
    "print(trainX.shape)\n",
    "#print(trainY.shape)\n",
    "#print(testX.shape)\n",
    "print(testY[5,])\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "print(testY[3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 270ms/step - loss: 1.5158 - accuracy: 0.2444 - val_loss: 1.5050 - val_accuracy: 0.3548\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.5061 - accuracy: 0.2444 - val_loss: 1.4956 - val_accuracy: 0.3548\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.4971 - accuracy: 0.2444 - val_loss: 1.4852 - val_accuracy: 0.3548\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.4894 - accuracy: 0.2444 - val_loss: 1.4748 - val_accuracy: 0.3548\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4817 - accuracy: 0.2444 - val_loss: 1.4666 - val_accuracy: 0.3548\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.4748 - accuracy: 0.2444 - val_loss: 1.4607 - val_accuracy: 0.3548\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4676 - accuracy: 0.2444 - val_loss: 1.4563 - val_accuracy: 0.3548\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.4607 - accuracy: 0.2444 - val_loss: 1.4474 - val_accuracy: 0.3548\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.4534 - accuracy: 0.2444 - val_loss: 1.4405 - val_accuracy: 0.3548\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.4498 - accuracy: 0.2444 - val_loss: 1.4391 - val_accuracy: 0.3548\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4422 - accuracy: 0.2444 - val_loss: 1.4343 - val_accuracy: 0.3548\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4379 - accuracy: 0.2444 - val_loss: 1.4315 - val_accuracy: 0.3548\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4336 - accuracy: 0.2444 - val_loss: 1.4260 - val_accuracy: 0.3548\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.4294 - accuracy: 0.2444 - val_loss: 1.4214 - val_accuracy: 0.3548\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4258 - accuracy: 0.2444 - val_loss: 1.4161 - val_accuracy: 0.3548\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.4216 - accuracy: 0.2444 - val_loss: 1.4125 - val_accuracy: 0.3548\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4181 - accuracy: 0.2444 - val_loss: 1.4124 - val_accuracy: 0.3548\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.4154 - accuracy: 0.2444 - val_loss: 1.4109 - val_accuracy: 0.3548\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.4121 - accuracy: 0.2444 - val_loss: 1.4084 - val_accuracy: 0.3548\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4102 - accuracy: 0.2444 - val_loss: 1.4098 - val_accuracy: 0.3548\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4072 - accuracy: 0.2444 - val_loss: 1.4084 - val_accuracy: 0.3548\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4047 - accuracy: 0.2444 - val_loss: 1.4084 - val_accuracy: 0.3548\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4023 - accuracy: 0.2444 - val_loss: 1.4079 - val_accuracy: 0.3548\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.4022 - accuracy: 0.2444 - val_loss: 1.4045 - val_accuracy: 0.3548\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.3995 - accuracy: 0.2444 - val_loss: 1.4031 - val_accuracy: 0.3548\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.3971 - accuracy: 0.2444 - val_loss: 1.4033 - val_accuracy: 0.3548\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.3964 - accuracy: 0.2444 - val_loss: 1.4041 - val_accuracy: 0.3548\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.3951 - accuracy: 0.2444 - val_loss: 1.4032 - val_accuracy: 0.3548\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.3934 - accuracy: 0.2444 - val_loss: 1.4032 - val_accuracy: 0.3548\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.3924 - accuracy: 0.2444 - val_loss: 1.4032 - val_accuracy: 0.3548\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.3916 - accuracy: 0.2444 - val_loss: 1.4047 - val_accuracy: 0.3548\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.3914 - accuracy: 0.2444 - val_loss: 1.4047 - val_accuracy: 0.3548\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.3901 - accuracy: 0.2444 - val_loss: 1.4043 - val_accuracy: 0.3548\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.3907 - accuracy: 0.2444 - val_loss: 1.4060 - val_accuracy: 0.3548\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3891 - accuracy: 0.2444 - val_loss: 1.4080 - val_accuracy: 0.3548\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3889 - accuracy: 0.2444 - val_loss: 1.4106 - val_accuracy: 0.3548\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.3874 - accuracy: 0.2444 - val_loss: 1.4104 - val_accuracy: 0.3548\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.3867 - accuracy: 0.2444 - val_loss: 1.4112 - val_accuracy: 0.3548\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3861 - accuracy: 0.2444 - val_loss: 1.4103 - val_accuracy: 0.3548\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3863 - accuracy: 0.2444 - val_loss: 1.4103 - val_accuracy: 0.3548\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.3867 - accuracy: 0.2333 - val_loss: 1.4079 - val_accuracy: 0.3548\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.3856 - accuracy: 0.2444 - val_loss: 1.4073 - val_accuracy: 0.3548\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.3851 - accuracy: 0.2444 - val_loss: 1.4075 - val_accuracy: 0.3548\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3852 - accuracy: 0.2444 - val_loss: 1.4094 - val_accuracy: 0.3548\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3845 - accuracy: 0.2444 - val_loss: 1.4103 - val_accuracy: 0.2581\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3841 - accuracy: 0.3111 - val_loss: 1.4101 - val_accuracy: 0.1290\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.3836 - accuracy: 0.2889 - val_loss: 1.4096 - val_accuracy: 0.1290\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.3838 - accuracy: 0.2889 - val_loss: 1.4104 - val_accuracy: 0.1290\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.3845 - accuracy: 0.2889 - val_loss: 1.4091 - val_accuracy: 0.1290\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.3834 - accuracy: 0.2889 - val_loss: 1.4100 - val_accuracy: 0.1290\n"
     ]
    }
   ],
   "source": [
    "# Desining of Neural Network and Training\n",
    "from keras.optimizers import Adam\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(1024, ),activation='sigmoid'))\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "model.add(Dense(75, activation='tanh'))\n",
    "model.add(Dense(75, activation='tanh'))\n",
    "model.add(Dense(75, activation='tanh'))\n",
    "model.add(Dense(75, activation='tanh'))\n",
    "model.add(Dense(75, activation='tanh'))\n",
    "model.add(Dense(75, activation='tanh'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(25, activation='tanh'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001), metrics=['accuracy'])\n",
    "model.fit(trainX, trainY, epochs=50, batch_size=32,validation_data=(testX, testY))\n",
    "import h5py\n",
    "model.save('Trained_FE_18-07.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction using Neural Network\n",
    "from keras.models import load_model\n",
    "label = [\"ANGRY\", \"DISGUST\", \"FEAR\", \"HAPPY\", \"NEUTRAL\", \"SAD\",\"SURPRISE\" ]\n",
    "model = load_model('Trained_FE_18-07.h5')\n",
    "samp = cv2.imread(\"images/angry27.jpg\")\n",
    "plt.imshow(samp)\n",
    "gsamp = cv2.cvtColor(samp, cv2.COLOR_BGR2GRAY)\n",
    "gsamp = cv2.resize(gsamp, (32, 32))\n",
    "gsamp = gsamp.reshape(1, 1024)\n",
    "data_samp = np.array(gsamp, dtype=\"float\") \n",
    "\n",
    "#test_x = test_x.reshape(4,)\n",
    "answer = model.predict(data_samp)\n",
    "print(answer)\n",
    "i = answer.argmax(axis=1)[0]\n",
    "print(label[int(i)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
